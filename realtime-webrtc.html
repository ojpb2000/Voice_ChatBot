<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Voice Chat with Jessica - WebRTC</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            max-width: 600px;
            width: 100%;
            text-align: center;
        }

        .header {
            margin-bottom: 30px;
        }

        .header h1 {
            color: #333;
            font-size: 2.5rem;
            margin-bottom: 10px;
        }

        .header p {
            color: #666;
            font-size: 1.1rem;
        }

        .status {
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 20px 0;
            padding: 15px;
            border-radius: 10px;
            font-weight: 500;
        }

        .status.disconnected {
            background: #f8f9fa;
            color: #6c757d;
            border: 2px solid #dee2e6;
        }

        .status.connecting {
            background: #fff3cd;
            color: #856404;
            border: 2px solid #ffeaa7;
        }

        .status.connected {
            background: #d4edda;
            color: #155724;
            border: 2px solid #c3e6cb;
        }

        .status.error {
            background: #f8d7da;
            color: #721c24;
            border: 2px solid #f5c6cb;
        }

        .status-indicator {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 10px;
            animation: pulse 2s infinite;
        }

        .status.disconnected .status-indicator {
            background: #6c757d;
        }

        .status.connecting .status-indicator {
            background: #ffc107;
        }

        .status.connected .status-indicator {
            background: #28a745;
        }

        .status.error .status-indicator {
            background: #dc3545;
        }

        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }

        .central-control {
            display: flex;
            justify-content: center;
            margin: 30px 0;
        }

        .central-btn {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-size: 2.5rem;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 8px 25px rgba(102, 126, 234, 0.3);
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .central-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 12px 35px rgba(102, 126, 234, 0.4);
        }

        .central-btn:active {
            transform: translateY(0);
        }

        .central-btn.connecting {
            background: linear-gradient(135deg, #ffc107 0%, #fd7e14 100%);
            animation: pulse 1s infinite;
        }

        .central-btn.connected {
            background: linear-gradient(135deg, #28a745 0%, #20c997 100%);
        }

        .central-btn.error {
            background: linear-gradient(135deg, #dc3545 0%, #e83e8c 100%);
        }

        .central-btn.disabled {
            background: #6c757d;
            cursor: not-allowed;
            opacity: 0.6;
        }

        .audio-visualizer {
            display: flex;
            justify-content: center;
            align-items: end;
            height: 60px;
            margin: 20px 0;
            gap: 3px;
        }

        .audio-bar {
            width: 4px;
            background: linear-gradient(to top, #667eea, #764ba2);
            border-radius: 2px;
            transition: height 0.1s ease;
        }

        .controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin: 20px 0;
        }

        .control-btn {
            padding: 12px 24px;
            border: none;
            border-radius: 25px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 1rem;
        }

        .btn-text-mode {
            background: #6c757d;
            color: white;
        }

        .btn-text-mode:hover {
            background: #5a6268;
        }

        .btn-logout {
            background: #dc3545;
            color: white;
        }

        .btn-logout:hover {
            background: #c82333;
        }

        .debug-panel {
            background: #f8f9fa;
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            text-align: left;
            font-family: 'Courier New', monospace;
            font-size: 12px;
            max-height: 300px;
            overflow-y: auto;
        }

        .debug-panel h3 {
            margin-bottom: 15px;
            color: #333;
            font-family: 'Segoe UI', sans-serif;
        }

        .debug-section {
            margin-bottom: 10px;
        }

        .debug-section h4 {
            color: #666;
            margin-bottom: 5px;
            font-family: 'Segoe UI', sans-serif;
        }

        .debug-events {
            max-height: 150px;
            overflow-y: auto;
            background: white;
            padding: 10px;
            border-radius: 5px;
            border: 1px solid #dee2e6;
        }

        .debug-event {
            margin-bottom: 5px;
            padding: 2px 5px;
            border-radius: 3px;
            font-size: 11px;
        }

        .debug-event.success {
            background: #d4edda;
            color: #155724;
        }

        .debug-event.error {
            background: #f8d7da;
            color: #721c24;
        }

        .debug-event.info {
            background: #d1ecf1;
            color: #0c5460;
        }

        .debug-event.warning {
            background: #fff3cd;
            color: #856404;
        }

        .latency-indicator {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(0,0,0,0.8);
            color: white;
            padding: 10px 15px;
            border-radius: 20px;
            font-family: 'Courier New', monospace;
            font-size: 12px;
            z-index: 1000;
        }

        .latency-indicator.good {
            background: rgba(40, 167, 69, 0.8);
        }

        .latency-indicator.warning {
            background: rgba(255, 193, 7, 0.8);
        }

        .latency-indicator.bad {
            background: rgba(220, 53, 69, 0.8);
        }

        @media (max-width: 768px) {
            .container {
                margin: 10px;
                padding: 20px;
            }
            
            .header h1 {
                font-size: 2rem;
            }
            
            .central-btn {
                width: 100px;
                height: 100px;
                font-size: 2rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üé§ Real-time Voice Chat</h1>
            <p>Ultra-low latency conversation with Jessica using WebRTC</p>
        </div>

        <div class="status disconnected" id="status">
            <div class="status-indicator"></div>
            <span id="statusText">Disconnected</span>
        </div>

        <div class="central-control">
            <button id="centralBtn" class="central-btn">
                <span class="btn-icon" id="centralIcon">üé§</span>
            </button>
        </div>

        <div class="audio-visualizer" id="audioVisualizer">
            <!-- Audio bars will be generated by JavaScript -->
        </div>

        <div class="controls">
            <button class="control-btn btn-text-mode" onclick="window.location.href='index.html'">
                üìù Text Mode
            </button>
            <button class="control-btn btn-logout" onclick="logout()">
                üö™ Logout
            </button>
        </div>

        <!-- Debug Panel -->
        <div class="debug-panel" id="debugPanel">
            <h3>üîç Real-time Debug Information</h3>
            <div class="debug-content">
                <div class="debug-section">
                    <h4>Connection Status:</h4>
                    <div id="debugConnection">Disconnected</div>
                </div>
                <div class="debug-section">
                    <h4>Audio Status:</h4>
                    <div id="debugAudio">Not initialized</div>
                </div>
                <div class="debug-section">
                    <h4>Processing Status:</h4>
                    <div id="debugProcessing">Idle</div>
                </div>
                <div class="debug-section">
                    <h4>Recent Events:</h4>
                    <div id="debugEvents" class="debug-events"></div>
                </div>
                <div class="debug-section">
                    <h4>Audio Buffer:</h4>
                    <div id="debugBuffer">0 chunks</div>
                </div>
            </div>
        </div>
    </div>

    <!-- Latency Indicator -->
    <div class="latency-indicator" id="latencyIndicator">
        Latency: --ms
    </div>

    <script>
        // Configuration
        const BACKEND_URL = 'https://voice-chatbot-a9u5.onrender.com';
        const AUDIO_CHUNK_SIZE = 200; // milliseconds
        const SAMPLE_RATE = 16000; // Hz for Whisper
        
        // State variables
        let isConnected = false;
        let isRecording = false;
        let audioContext = null;
        let mediaRecorder = null;
        let audioStream = null;
        let analyser = null;
        let microphone = null;
        let animationId = null;
        let audioQueue = [];
        let isProcessing = false;
        
        // Debug elements
        const debugConnection = document.getElementById('debugConnection');
        const debugAudio = document.getElementById('debugAudio');
        const debugProcessing = document.getElementById('debugProcessing');
        const debugEvents = document.getElementById('debugEvents');
        const debugBuffer = document.getElementById('debugBuffer');
        const latencyIndicator = document.getElementById('latencyIndicator');
        
        // UI elements
        const status = document.getElementById('status');
        const statusText = document.getElementById('statusText');
        const centralBtn = document.getElementById('centralBtn');
        const centralIcon = document.getElementById('centralIcon');
        const audioVisualizer = document.getElementById('audioVisualizer');
        
        // Initialize
        document.addEventListener('DOMContentLoaded', () => {
            // Check authentication
            if (!sessionStorage.getItem('authenticated')) {
                window.location.href = 'login.html';
                return;
            }
            
            setupAudioVisualizer();
            updateDebugInfo();
        });
        
        // Central button click handler
        centralBtn.addEventListener('click', async () => {
            if (!isConnected) {
                await startRealtimeCall();
            } else {
                endRealtimeCall();
            }
        });
        
        async function startRealtimeCall() {
            try {
                updateStatus('connecting', 'Connecting...');
                updateCentralButton('connecting', '‚è≥');
                addDebugEvent('Starting real-time call...', 'info');
                
                // Request microphone access
                addDebugEvent('Requesting microphone access...', 'info');
                audioStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: SAMPLE_RATE,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });
                addDebugEvent('Microphone access granted', 'success');
                
                // Create AudioContext
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: SAMPLE_RATE
                });
                
                // Resume audio context if suspended
                if (audioContext.state === 'suspended') {
                    await audioContext.resume();
                    addDebugEvent('Audio context resumed', 'info');
                }
                
                // Setup audio processing
                setupAudioProcessing();
                setupAudioVisualizer();
                
                // Start recording
                startRecording();
                
                isConnected = true;
                updateStatus('connected', 'Connected - Ready to talk!');
                updateCentralButton('connected', 'üéôÔ∏è');
                addDebugEvent('Real-time call started successfully', 'success');
                
            } catch (error) {
                console.error('Failed to start real-time call:', error);
                addDebugEvent(`Failed to start: ${error.message}`, 'error');
                updateStatus('error', `Failed to connect: ${error.message}`);
                updateCentralButton('error', '‚ùå');
            }
        }
        
        function setupAudioProcessing() {
            // Create analyser for visualization
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 256;
            analyser.smoothingTimeConstant = 0.8;
            
            // Create microphone source
            microphone = audioContext.createMediaStreamSource(audioStream);
            microphone.connect(analyser);
            
            addDebugEvent('Audio processing setup complete', 'success');
        }
        
        function setupAudioVisualizer() {
            // Clear existing bars
            audioVisualizer.innerHTML = '';
            
            // Create audio bars
            for (let i = 0; i < 32; i++) {
                const bar = document.createElement('div');
                bar.className = 'audio-bar';
                bar.style.height = '2px';
                audioVisualizer.appendChild(bar);
            }
            
            // Start animation
            animateAudioVisualizer();
        }
        
        function animateAudioVisualizer() {
            if (!analyser) return;
            
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteFrequencyData(dataArray);
            
            const bars = audioVisualizer.querySelectorAll('.audio-bar');
            const step = Math.floor(dataArray.length / bars.length);
            
            bars.forEach((bar, index) => {
                const value = dataArray[index * step];
                const height = Math.max(2, (value / 255) * 60);
                bar.style.height = `${height}px`;
            });
            
            animationId = requestAnimationFrame(animateAudioVisualizer);
        }
        
        function startRecording() {
            try {
                // Create MediaRecorder with small chunks for real-time processing
                mediaRecorder = new MediaRecorder(audioStream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                
                mediaRecorder.ondataavailable = async (event) => {
                    if (event.data.size > 0) {
                        await processAudioChunk(event.data);
                    }
                };
                
                // Start recording with small time slices for real-time processing
                mediaRecorder.start(AUDIO_CHUNK_SIZE);
                isRecording = true;
                
                addDebugEvent(`Recording started with ${AUDIO_CHUNK_SIZE}ms chunks`, 'success');
                updateDebugInfo();
                
            } catch (error) {
                console.error('Failed to start recording:', error);
                addDebugEvent(`Recording failed: ${error.message}`, 'error');
            }
        }
        
        async function processAudioChunk(audioBlob) {
            if (isProcessing) {
                // Queue the chunk if we're still processing
                audioQueue.push(audioBlob);
                addDebugEvent(`Audio chunk queued (${audioQueue.length} in queue)`, 'warning');
                return;
            }
            
            isProcessing = true;
            updateDebugProcessing('Processing audio...');
            
            const startTime = Date.now();
            
            try {
                // Convert blob to base64
                const base64Audio = await blobToBase64(audioBlob);
                
                // Send to Whisper for transcription
                const transcription = await transcribeAudio(base64Audio);
                
                if (transcription && transcription.trim().length > 0) {
                    addDebugEvent(`Transcribed: "${transcription}"`, 'info');
                    
                    // Get response from GPT
                    const response = await getGPTResponse(transcription);
                    
                    if (response) {
                        addDebugEvent(`GPT Response: "${response}"`, 'info');
                        
                        // Convert response to speech
                        await speakText(response);
                    }
                }
                
                // Calculate and display latency
                const latency = Date.now() - startTime;
                updateLatencyIndicator(latency);
                addDebugEvent(`Processing completed in ${latency}ms`, 'success');
                
            } catch (error) {
                console.error('Error processing audio chunk:', error);
                addDebugEvent(`Processing error: ${error.message}`, 'error');
            } finally {
                isProcessing = false;
                updateDebugProcessing('Idle');
                
                // Process queued chunks
                if (audioQueue.length > 0) {
                    const nextChunk = audioQueue.shift();
                    addDebugEvent(`Processing queued chunk (${audioQueue.length} remaining)`, 'info');
                    setTimeout(() => processAudioChunk(nextChunk), 100);
                }
                
                updateDebugInfo();
            }
        }
        
        async function transcribeAudio(base64Audio) {
            try {
                const response = await fetch(`${BACKEND_URL}/api/transcribe`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        audio: base64Audio,
                        model: 'whisper-1'
                    })
                });
                
                if (!response.ok) {
                    throw new Error(`Transcription failed: ${response.status}`);
                }
                
                const result = await response.json();
                return result.text;
                
            } catch (error) {
                console.error('Transcription error:', error);
                throw error;
            }
        }
        
        async function getGPTResponse(text) {
            try {
                const response = await fetch(`${BACKEND_URL}/api/chat`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        message: text
                    })
                });
                
                if (!response.ok) {
                    throw new Error(`GPT request failed: ${response.status}`);
                }
                
                const result = await response.json();
                return result.response;
                
            } catch (error) {
                console.error('GPT error:', error);
                throw error;
            }
        }
        
        async function speakText(text) {
            return new Promise((resolve) => {
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.rate = 1.0;
                utterance.pitch = 1.0;
                utterance.volume = 1.0;
                
                // Try to use a female voice
                const voices = speechSynthesis.getVoices();
                const femaleVoice = voices.find(voice => 
                    voice.name.toLowerCase().includes('female') ||
                    voice.name.toLowerCase().includes('woman') ||
                    voice.name.toLowerCase().includes('zira') ||
                    voice.name.toLowerCase().includes('susan')
                );
                
                if (femaleVoice) {
                    utterance.voice = femaleVoice;
                }
                
                utterance.onend = () => resolve();
                utterance.onerror = () => resolve();
                
                speechSynthesis.speak(utterance);
            });
        }
        
        function blobToBase64(blob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onload = () => {
                    const base64 = reader.result.split(',')[1];
                    resolve(base64);
                };
                reader.onerror = reject;
                reader.readAsDataURL(blob);
            });
        }
        
        function updateLatencyIndicator(latency) {
            latencyIndicator.textContent = `Latency: ${latency}ms`;
            
            if (latency < 500) {
                latencyIndicator.className = 'latency-indicator good';
            } else if (latency < 1000) {
                latencyIndicator.className = 'latency-indicator warning';
            } else {
                latencyIndicator.className = 'latency-indicator bad';
            }
        }
        
        function endRealtimeCall() {
            console.log('Ending real-time call...');
            
            // Stop recording
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
            }
            
            // Stop audio stream
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
                audioStream = null;
            }
            
            // Cleanup audio context
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            // Stop animation
            if (animationId) {
                cancelAnimationFrame(animationId);
                animationId = null;
            }
            
            // Reset state
            isConnected = false;
            isProcessing = false;
            audioQueue = [];
            
            // Update UI
            updateStatus('disconnected', 'Disconnected');
            updateCentralButton('disconnected', 'üé§');
            addDebugEvent('Real-time call ended', 'info');
            
            console.log('Real-time call ended');
        }
        
        function updateStatus(type, text) {
            status.className = `status ${type}`;
            statusText.textContent = text;
        }
        
        function updateCentralButton(type, icon) {
            centralBtn.className = `central-btn ${type}`;
            centralIcon.textContent = icon;
        }
        
        function updateDebugProcessing(status) {
            debugProcessing.textContent = status;
        }
        
        function addDebugEvent(message, type = 'info') {
            const timestamp = new Date().toLocaleTimeString();
            const eventDiv = document.createElement('div');
            eventDiv.className = `debug-event ${type}`;
            eventDiv.textContent = `${timestamp}: ${message}`;
            
            debugEvents.insertBefore(eventDiv, debugEvents.firstChild);
            
            // Keep only last 20 events
            while (debugEvents.children.length > 20) {
                debugEvents.removeChild(debugEvents.lastChild);
            }
        }
        
        function updateDebugInfo() {
            // Update connection status
            debugConnection.textContent = isConnected ? 'Connected' : 'Disconnected';
            
            // Update audio status
            if (audioContext && audioContext.state === 'running') {
                if (isRecording) {
                    debugAudio.textContent = 'Context: running, Recording: Active';
                } else {
                    debugAudio.textContent = 'Context: running, Recording: Inactive';
                }
            } else if (audioContext) {
                debugAudio.textContent = `Context: ${audioContext.state}, Recording: Inactive`;
            } else {
                debugAudio.textContent = 'Not initialized';
            }
            
            // Update buffer status
            debugBuffer.textContent = `${audioQueue.length} chunks queued`;
        }
        
        function logout() {
            sessionStorage.removeItem('authenticated');
            window.location.href = 'login.html';
        }
    </script>
</body>
</html>
