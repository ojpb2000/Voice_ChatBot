<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Realtime Chat - Jessica Taylor</title>
    <link rel="stylesheet" href="style.css?v=4">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        .mode-toggle {
            position: fixed;
            top: 20px;
            right: 20px;
            z-index: 1000;
        }
        .mode-btn {
            background: #667eea;
            color: white;
            border: none;
            padding: 10px 15px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 14px;
            transition: all 0.2s ease;
        }
        .mode-btn:hover {
            background: #5a67d8;
            transform: translateY(-1px);
        }
        .realtime-container {
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            text-align: center;
        }
        .status-card {
            background: white;
            border-radius: 16px;
            padding: 30px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.1);
            margin-bottom: 30px;
        }
        .status-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 8px;
        }
        .status-connecting { background: #fbbf24; }
        .status-connected { background: #10b981; }
        .status-error { background: #ef4444; }
        .status-disconnected { background: #6b7280; }
        .control-panel {
            display: flex;
            gap: 20px;
            justify-content: center;
            margin: 30px 0;
        }
        .control-btn {
            padding: 15px 30px;
            border: none;
            border-radius: 12px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        .btn-connect {
            background: #10b981;
            color: white;
        }
        .btn-connect:hover:not(:disabled) {
            background: #059669;
            transform: translateY(-2px);
        }
        .btn-disconnect {
            background: #ef4444;
            color: white;
        }
        .btn-disconnect:hover:not(:disabled) {
            background: #dc2626;
            transform: translateY(-2px);
        }
        .btn-mute {
            background: #f59e0b;
            color: white;
        }
        .btn-mute:hover:not(:disabled) {
            background: #d97706;
            transform: translateY(-2px);
        }
        .btn-unmute {
            background: #6366f1;
            color: white;
        }
        .btn-unmute:hover:not(:disabled) {
            background: #4f46e5;
            transform: translateY(-2px);
        }
        .control-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none !important;
        }
        .audio-visualizer {
            width: 200px;
            height: 60px;
            margin: 20px auto;
            background: #f3f4f6;
            border-radius: 8px;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 3px;
        }
        .audio-bar {
            width: 4px;
            background: #667eea;
            border-radius: 2px;
            transition: height 0.1s ease;
        }
        .instructions {
            background: #f8fafc;
            border-left: 4px solid #667eea;
            padding: 20px;
            margin: 30px 0;
            border-radius: 8px;
            text-align: left;
        }
        .instructions h3 {
            margin-top: 0;
            color: #374151;
        }
        .instructions ul {
            margin: 10px 0;
            padding-left: 20px;
        }
        .instructions li {
            margin: 8px 0;
            color: #6b7280;
        }
    </style>
</head>
<body>
    <div class="mode-toggle">
        <button class="mode-btn" onclick="window.location.href='index.html'">
            üìù Text Mode
        </button>
    </div>

    <div class="realtime-container">
        <div class="status-card">
            <h1>üé§ Realtime Chat with Jessica</h1>
            <p>Full-duplex voice conversation with low latency</p>
            
            <div class="status-indicator" id="statusIndicator"></div>
            <span id="statusText">Disconnected</span>
        </div>

        <div class="control-panel">
            <button id="connectBtn" class="control-btn btn-connect">
                üé§ Start Call
            </button>
            <button id="disconnectBtn" class="control-btn btn-disconnect" disabled>
                üìû End Call
            </button>
            <button id="muteBtn" class="control-btn btn-mute" disabled>
                üîá Mute
            </button>
        </div>

        <div class="audio-visualizer" id="audioVisualizer">
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
        </div>

        <div class="instructions">
            <h3>How to use Realtime Mode:</h3>
            <ul>
                <li><strong>Click "Start Call"</strong> to begin a voice conversation</li>
                <li><strong>Speak naturally</strong> - Jessica will respond in real-time</li>
                <li><strong>Barge-in supported</strong> - you can interrupt her anytime</li>
                <li><strong>Mute/Unmute</strong> your microphone as needed</li>
                <li><strong>Click "End Call"</strong> to disconnect</li>
            </ul>
        </div>
    </div>

    <script>
        // Configuration
        const BACKEND_URL = 'https://voice-chatbot-a9u5.onrender.com';
        
        // State
        let websocket = null;
        let isConnected = false;
        let isMuted = false;
        let audioContext = null;
        let analyser = null;
        let microphone = null;
        let mediaRecorder = null;
        let audioChunks = [];
        let sessionId = null;
        let audioQueue = [];
        let audioPlaying = false;
        
        // DOM elements
        const statusIndicator = document.getElementById('statusIndicator');
        const statusText = document.getElementById('statusText');
        const connectBtn = document.getElementById('connectBtn');
        const disconnectBtn = document.getElementById('disconnectBtn');
        const muteBtn = document.getElementById('muteBtn');
        const audioVisualizer = document.getElementById('audioVisualizer');
        const audioBars = audioVisualizer.querySelectorAll('.audio-bar');
        
        // Initialize
        document.addEventListener('DOMContentLoaded', () => {
            setupEventListeners();
            updateStatus('disconnected', 'Disconnected');
        });
        
        function setupEventListeners() {
            connectBtn.addEventListener('click', startRealtimeCall);
            disconnectBtn.addEventListener('click', endRealtimeCall);
            muteBtn.addEventListener('click', toggleMute);
        }
        
        async function startRealtimeCall() {
            try {
                updateStatus('connecting', 'Connecting...');
                connectBtn.disabled = true;
                
                // Get session token from backend
                const response = await fetch(`${BACKEND_URL}/api/realtime/session`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' }
                });
                
                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}: ${await response.text()}`);
                }
                
                // Connect to our WebSocket proxy (same port as HTTP)
                const wsUrl = `wss://voice-chatbot-a9u5.onrender.com`;
                websocket = new WebSocket(wsUrl);
                
                websocket.onopen = () => {
                    console.log('WebSocket connected to proxy');
                    
                    // Send connect message to proxy
                    websocket.send(JSON.stringify({
                        type: 'connect'
                    }));
                    console.log('Sent connect message to proxy');
                };
                
                websocket.onmessage = (event) => {
                    // Handle both JSON messages and binary data
                    let data;
                    try {
                        data = JSON.parse(event.data);
                        console.log('Received JSON:', data);
                    } catch (e) {
                        // Handle binary data (audio)
                        console.log('Received binary data (audio)');
                        if (event.data instanceof Blob) {
                            // This is audio data from OpenAI
                            const reader = new FileReader();
                            reader.onload = () => {
                                const audioData = reader.result;
                                // Convert ArrayBuffer to Uint8Array and add to queue
                                const pcmData = new Uint8Array(audioData);
                                audioQueue.push(pcmData);
                                console.log('Binary audio added to queue, queue length:', audioQueue.length);
                                if (!audioPlaying) {
                                    playNextAudio();
                                }
                            };
                            reader.readAsArrayBuffer(event.data);
                        }
                        return;
                    }
                    
                    switch (data.type) {
                        case 'connected':
                            console.log('Connected to OpenAI Realtime via proxy');
                            updateStatus('connected', 'Connected - Ready to talk!');
                            connectBtn.disabled = false;
                            disconnectBtn.disabled = false;
                            muteBtn.disabled = false;
                            isConnected = true;
                            
                            // Initialize audio context with user interaction
                            if (!audioContext) {
                                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                            }
                            
                            // Resume audio context if suspended
                            if (audioContext.state === 'suspended') {
                                audioContext.resume().then(() => {
                                    console.log('Audio context resumed');
                                });
                            }
                            
                            setupMicrophone();
                            break;
                        case 'session.created':
                            console.log('Session created:', data.session);
                            break;
                        case 'session.updated':
                            console.log('Session updated:', data.session);
                            break;
                        case 'conversation.item.input_audio_buffer.committed':
                            console.log('Input audio committed');
                            break;
                        case 'conversation.item.output_audio_buffer.committed':
                            console.log('Output audio committed, audio length:', data.audio ? data.audio.length : 'none');
                            if (data.audio) {
                                // data.audio is base64 encoded PCM data
                                try {
                                    const binaryString = atob(data.audio);
                                    const pcmData = new Uint8Array(binaryString.length);
                                    for (let i = 0; i < binaryString.length; i++) {
                                        pcmData[i] = binaryString.charCodeAt(i);
                                    }
                                    audioQueue.push(pcmData);
                                    console.log('Base64 audio decoded and added to queue, queue length:', audioQueue.length);
                                    if (!audioPlaying) {
                                        playNextAudio();
                                    }
                                } catch (e) {
                                    console.error('Failed to decode base64 audio:', e);
                                }
                            }
                            break;
                        case 'conversation.item.output_audio_buffer.speech_started':
                            console.log('Jessica started speaking');
                            updateStatus('connected', 'Jessica is speaking...');
                            break;
                        case 'conversation.item.output_audio_buffer.speech_stopped':
                            console.log('Jessica stopped speaking');
                            updateStatus('connected', 'Connected - Ready to talk!');
                            break;
                        case 'conversation.item.transcript.completed':
                            console.log('Transcript:', data.transcript);
                            break;
                        case 'error':
                            console.error('WebSocket error:', data.error);
                            updateStatus('error', `Error: ${data.error.message}`);
                            break;
                    }
                };
                
                websocket.onclose = (event) => {
                    console.log('WebSocket disconnected, code:', event.code, 'reason:', event.reason);
                    updateStatus('disconnected', 'Disconnected');
                    connectBtn.disabled = false;
                    disconnectBtn.disabled = true;
                    muteBtn.disabled = true;
                    isConnected = false;
                    cleanupAudioVisualizer();
                    cleanupMicrophone();
                };
                
                websocket.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    updateStatus('error', 'Connection error');
                    connectBtn.disabled = false;
                };
                
            } catch (error) {
                console.error('Failed to start realtime call:', error);
                updateStatus('error', `Failed to connect: ${error.message}`);
                connectBtn.disabled = false;
            }
        }
        
        async function endRealtimeCall() {
            console.log('Ending realtime call...');
            
            if (websocket) {
                websocket.close();
                websocket = null;
            }
            
            isConnected = false;
            audioQueue = [];
            audioPlaying = false;
            
            cleanupAudioVisualizer();
            cleanupMicrophone();
            
            // Update UI
            updateStatus('disconnected', 'Disconnected');
            connectBtn.disabled = false;
            disconnectBtn.disabled = true;
            muteBtn.disabled = true;
            
            console.log('Realtime call ended');
        }
        
        function toggleMute() {
            if (!websocket) return;
            
            isMuted = !isMuted;
            
            if (isMuted) {
                stopMicrophone();
                muteBtn.innerHTML = 'üîä Unmute';
                muteBtn.className = 'control-btn btn-unmute';
            } else {
                setupMicrophone();
                muteBtn.innerHTML = 'üîá Mute';
                muteBtn.className = 'control-btn btn-mute';
            }
        }
        
        async function setupMicrophone() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 24000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });
                
                // Create MediaRecorder for audio capture
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    sendAudioToServer(audioBlob);
                };
                
                // Start recording
                mediaRecorder.start(100); // Record in 100ms chunks
                
                // Setup audio visualizer
                setupAudioVisualizer();
                
            } catch (error) {
                console.error('Microphone setup failed:', error);
                updateStatus('error', 'Microphone access denied');
            }
        }
        
        function stopMicrophone() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
        }
        
        function cleanupMicrophone() {
            if (mediaRecorder) {
                if (mediaRecorder.state === 'recording') {
                    mediaRecorder.stop();
                }
                mediaRecorder = null;
            }
            audioChunks = [];
        }
        
        async function sendAudioToServer(audioBlob) {
            if (!websocket || websocket.readyState !== WebSocket.OPEN) return;
            
            try {
                // Convert audio to base64
                const arrayBuffer = await audioBlob.arrayBuffer();
                const base64Audio = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));
                
                // Send audio to WebSocket
                websocket.send(JSON.stringify({
                    type: 'conversation.item.input_audio_buffer.append',
                    audio: base64Audio
                }));
                
                // Commit the audio buffer
                websocket.send(JSON.stringify({
                    type: 'conversation.item.input_audio_buffer.commit'
                }));
                
            } catch (error) {
                console.error('Failed to send audio:', error);
            }
        }
        
        function updateStatus(type, text) {
            statusIndicator.className = `status-indicator status-${type}`;
            statusText.textContent = text;
        }
        
        function setupAudioVisualizer() {
            try {
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }
                if (!analyser) {
                    analyser = audioContext.createAnalyser();
                    analyser.fftSize = 256;
                }
                
                // Use the existing microphone stream from mediaRecorder
                if (mediaRecorder && mediaRecorder.stream) {
                    microphone = audioContext.createMediaStreamSource(mediaRecorder.stream);
                    microphone.connect(analyser);
                    animateAudioVisualizer();
                }
            } catch (error) {
                console.error('Audio visualizer setup failed:', error);
            }
        }
        
        function cleanupAudioVisualizer() {
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            if (microphone) {
                microphone.disconnect();
                microphone = null;
            }
            analyser = null;
        }
        
        function animateAudioVisualizer() {
            if (!analyser) return;
            
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            
            function draw() {
                if (!analyser) return;
                
                analyser.getByteFrequencyData(dataArray);
                
                // Update audio bars
                audioBars.forEach((bar, index) => {
                    const value = dataArray[index * 8] || 0;
                    const height = Math.max(4, (value / 255) * 50);
                    bar.style.height = `${height}px`;
                });
                
                requestAnimationFrame(draw);
            }
            
            draw();
        }
        

        function playPCMAudio(pcmData) {
            try {
                console.log('Audio context state:', audioContext ? audioContext.state : 'not created');
                console.log('PCM data length:', pcmData.length);
                
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    console.log('Created new audio context');
                }
                
                // Resume audio context if suspended
                if (audioContext.state === 'suspended') {
                    audioContext.resume().then(() => {
                        console.log('Audio context resumed, now playing audio');
                        playPCMAudioInternal(pcmData);
                    });
                    return;
                }
                
                playPCMAudioInternal(pcmData);
                
            } catch (error) {
                console.warn('Web Audio API failed, trying fallback:', error);
                playAudioFallback(pcmData);
            }
        }

        function playPCMAudioInternal(pcmData) {
            try {
                // Convert PCM data to Float32Array
                const samples = new Float32Array(pcmData.length / 2);
                for (let i = 0; i < samples.length; i++) {
                    // Convert 16-bit PCM to float (-1.0 to 1.0)
                    const sample = (pcmData[i * 2] | (pcmData[i * 2 + 1] << 8));
                    samples[i] = sample < 32768 ? sample / 32768 : (sample - 65536) / 32768;
                }
                
                console.log('Converted to samples:', samples.length, 'max amplitude:', Math.max(...samples.map(Math.abs)));
                
                // Create audio buffer
                const audioBuffer = audioContext.createBuffer(1, samples.length, 24000); // 24kHz sample rate
                audioBuffer.copyToChannel(samples, 0);
                
                // Create and play audio source
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                
                source.onended = () => {
                    console.log('Audio playback ended');
                    audioPlaying = false;
                    // Send confirmation that audio was played
                    if (websocket && websocket.readyState === WebSocket.OPEN) {
                        try {
                            websocket.send(JSON.stringify({
                                type: 'conversation.item.output_audio_buffer.done'
                            }));
                            console.log('Sent output_audio_buffer.done after Web Audio API playback');
                        } catch (e) {
                            console.warn('Failed to send audio confirmation:', e);
                        }
                    } else {
                        console.warn('WebSocket not open, cannot send audio confirmation');
                    }
                    playNextAudio();
                };
                
                source.start();
                audioPlaying = true;
                console.log('Playing PCM audio via Web Audio API, duration:', audioBuffer.duration, 'seconds');
                
            } catch (error) {
                console.warn('Internal audio playback failed:', error);
                playAudioFallback(pcmData);
            }
        }

        function playAudioFallback(pcmData) {
            try {
                const wavData = createWAVFile(pcmData);
                const audioBlob = new Blob([wavData], { type: 'audio/wav' });
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = new Audio(audioUrl);
                
                audio.volume = 1.0; // Ensure volume is at maximum
                
                audio.onended = () => {
                    console.log('Fallback audio playback ended');
                    URL.revokeObjectURL(audioUrl);
                    audioPlaying = false;
                    // Send confirmation that audio was played
                    if (websocket && websocket.readyState === WebSocket.OPEN) {
                        try {
                            websocket.send(JSON.stringify({
                                type: 'conversation.item.output_audio_buffer.done'
                            }));
                            console.log('Sent output_audio_buffer.done after fallback audio playback');
                        } catch (e) {
                            console.warn('Failed to send fallback audio confirmation:', e);
                        }
                    } else {
                        console.warn('WebSocket not open, cannot send fallback audio confirmation');
                    }
                    playNextAudio();
                };
                
                audio.onerror = (e) => {
                    console.warn('Fallback audio also failed:', e);
                    URL.revokeObjectURL(audioUrl);
                    audioPlaying = false;
                    playNextAudio();
                };
                
                audio.play().then(() => {
                    console.log('Fallback audio started playing');
                }).catch((e) => {
                    console.warn('Audio play failed:', e);
                    audioPlaying = false;
                    playNextAudio();
                });
                
                audioPlaying = true;
            } catch (e) {
                console.warn('All audio methods failed:', e);
                audioPlaying = false;
                playNextAudio();
            }
        }

        function createWAVFile(pcmData) {
            const sampleRate = 24000;
            const numChannels = 1;
            const bitsPerSample = 16;
            const blockAlign = numChannels * bitsPerSample / 8;
            const byteRate = sampleRate * blockAlign;
            const dataSize = pcmData.length;
            const fileSize = 44 + dataSize;
            
            const buffer = new ArrayBuffer(44 + dataSize);
            const view = new DataView(buffer);
            
            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, fileSize - 8, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, byteRate, true);
            view.setUint16(32, blockAlign, true);
            view.setUint16(34, bitsPerSample, true);
            writeString(36, 'data');
            view.setUint32(40, dataSize, true);
            
            // Copy PCM data
            const uint8View = new Uint8Array(buffer, 44);
            uint8View.set(pcmData);
            
            return buffer;
        }

        function playNextAudio() {
            if (audioQueue.length > 0 && !audioPlaying) {
                const nextAudio = audioQueue.shift(); // nextAudio is now a Uint8Array
                playPCMAudio(nextAudio); // Call playPCMAudio directly
            } else if (audioQueue.length === 0 && !audioPlaying) {
                // No more audio to play, send confirmation
                if (websocket && websocket.readyState === WebSocket.OPEN) {
                    try {
                        websocket.send(JSON.stringify({
                            type: 'conversation.item.output_audio_buffer.done'
                        }));
                        console.log('Sent output_audio_buffer.done as queue is empty and not playing.');
                    } catch (e) {
                        console.warn('Failed to send queue empty confirmation:', e);
                    }
                } else {
                    console.warn('WebSocket not open, cannot send queue empty confirmation');
                }
            }
        }
    </script>
</body>
</html>
